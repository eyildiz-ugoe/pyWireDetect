{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"model1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lTW8YEx-qIa9"},"source":["# Description\n","This notebook trains and evaluates the **EfficientNet** model."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YfU59FXOrEQ5"},"source":["# MOUNT GOOGLE Drive\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L60qoWhx8u1N","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"filUtUgerXRq"},"source":["# Change your working directory"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R3aN7xhNqgOn","colab":{}},"source":[" cd /content/gdrive/My\\ Drive/WIRE_DETECTION/TPU_COLAB/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ljwm42FBs-b","colab_type":"text"},"source":["# MODEL SPEC"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YQhJM4IrnbI6","colab":{}},"source":["model_name='efficientnetb7'\n","iden='model1'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zfrQJj1Gqxx6"},"source":["# TPU CHECK\n","The model trains faster in TPU (approximately 17 times)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MEkaY0jqfP5T","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","print(\"Tensorflow version \" + tf.__version__)\n","\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","except ValueError:\n","  raise BaseException('ERROR: Not connected to a TPU runtime;')\n","\n","tf.config.experimental_connect_to_cluster(tpu)\n","tf.tpu.experimental.initialize_tpu_system(tpu)\n","tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ocr7RR6jsBXG"},"source":["# FIXED PARAMETERS\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SynPRxh2o0m9","colab":{}},"source":["from glob import glob \n","import os \n","\n","BUCKET='tfalldata' # @param\n","TFIDEN='WireDTF'  # @param\n","IMG_DIM=256 # @param\n","NB_CHANNEL=3 # @param\n","BATCH_SIZE=128 # @param\n","BUFFER_SIZE=2048 # @param\n","TRAIN_DATA=1024*21 # @param\n","EVAL_DATA=1024*2 # @param\n","EPOCHS=250 # @param\n","TOTAL_DATA=TRAIN_DATA+EVAL_DATA\n","STEPS_PER_EPOCH = TOTAL_DATA//BATCH_SIZE\n","EVAL_STEPS      = EVAL_DATA//BATCH_SIZE\n","GCS_PATH='gs://{}/{}'.format(BUCKET,TFIDEN)\n","print(GCS_PATH)\n","\n","WEIGHT_PATH=os.path.join(os.getcwd(),'model_weights','{}.h5'.format(iden))\n","if os.path.exists(WEIGHT_PATH):\n","  print('FOUND PRETRAINED WEIGHTS')\n","  LOAD_WEIGHTS=True \n","else:\n","  print('NO PRETRAINED WEIGHTS FOUND')\n","  LOAD_WEIGHTS=False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jATm2xu_sKVK"},"source":["# Dataset wrapper with tf.data api"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BuT6HPWV2vLb","colab":{}},"source":["def data_input_fn(mode,BUFFER_SIZE,BATCH_SIZE,img_dim): \n","    \n","    def _parser(example):\n","        feature ={  'image'  : tf.io.FixedLenFeature([],tf.string) ,\n","                    'target' : tf.io.FixedLenFeature([],tf.string)\n","        }    \n","        parsed_example=tf.io.parse_single_example(example,feature)\n","        image_raw=parsed_example['image']\n","        image=tf.image.decode_png(image_raw,channels=3)\n","        image=tf.cast(image,tf.float32)/255.0\n","        image=tf.reshape(image,(img_dim,img_dim,3))\n","        \n","        \n","        target_raw=parsed_example['target']\n","        target=tf.image.decode_png(target_raw,channels=1)\n","        target=tf.cast(target,tf.float32)/255.0\n","        target=tf.reshape(target,(img_dim,img_dim,1))\n","        \n","        return image,target\n","    gcs_pattern=os.path.join(GCS_PATH,mode,'*.tfrecord')\n","    file_paths = tf.io.gfile.glob(gcs_pattern)\n","    dataset = tf.data.TFRecordDataset(file_paths)\n","    dataset = dataset.map(_parser)\n","    dataset = dataset.shuffle(BUFFER_SIZE,reshuffle_each_iteration=True)\n","    dataset = dataset.repeat()\n","    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n","    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","    return dataset\n","eval_ds = data_input_fn(\"Eval\",BUFFER_SIZE,BATCH_SIZE,IMG_DIM)\n","train_ds = data_input_fn(\"Train\",BUFFER_SIZE,BATCH_SIZE,IMG_DIM)\n","for x,y in eval_ds.take(1):\n","  print(x.shape)\n","  print(y.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XwNCEjsesRit"},"source":["# install segmentation-models"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q-bA5hWXTp4C","colab":{}},"source":["!pip3 install segmentation-models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nQozX2jssbHm"},"source":["# framework setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8U3DDIOlTs3G","colab":{}},"source":["import segmentation_models as sm\n","sm.set_framework('tf.keras')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OXowKzxMsd8W"},"source":["# model creation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GwHcjhf8qyZg","colab":{}},"source":["def ssim(y_true, y_pred):\n","  return tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n","\n","with tpu_strategy.scope():\n","  model = sm.Unet(model_name,input_shape=(IMG_DIM,IMG_DIM,NB_CHANNEL), encoder_weights=None)\n","  model.compile(optimizer=\"Adam\",\n","                loss=tf.keras.losses.mean_squared_error,\n","                metrics=[ssim])\n","  if LOAD_WEIGHTS:\n","    model.load_weights(WEIGHT_PATH)\n","model.summary()\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vjnppw11ssA_"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PCW_-2verNfJ","colab":{}},"source":["import numpy as np \n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","# reduces learning rate on plateau\n","lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1,\n","                               cooldown= 10,\n","                               patience=10,\n","                               verbose =1,\n","                               min_lr=0.1e-5)\n","\n","mode_autosave = tf.keras.callbacks.ModelCheckpoint(WEIGHT_PATH,\n","                                                  monitor='val_ssim', \n","                                                  mode = 'max', \n","                                                  save_best_only=True, \n","                                                  verbose=1, \n","                                                  period =10)\n","\n","# stop learining as metric on validatopn stop increasing\n","early_stopping = tf.keras.callbacks.EarlyStopping(patience=15, \n","                               verbose=1, \n","                               mode = 'auto') \n","\n","callbacks = [mode_autosave, lr_reducer,early_stopping ]\n","\n","\n","\n","history = model.fit(train_ds,\n","                    steps_per_epoch=STEPS_PER_EPOCH,\n","                    epochs=EPOCHS,\n","                    verbose=1,\n","                    validation_data=eval_ds,\n","                    validation_steps=EVAL_STEPS,\n","                    callbacks=callbacks)\n","\n","# save model\n","model.save_weights(WEIGHT_PATH)\n","def plot_history(history):\n","  \"\"\"\n","  Plots model training history \n","  \"\"\"\n","  fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\n","  ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n","  ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n","  ax_loss.legend()\n","  ax_acc.plot(history.epoch, history.history[\"ssim\"], label=\"Train ssim\")\n","  ax_acc.plot(history.epoch, history.history[\"val_ssim\"], label=\"Validation ssim\")\n","  ax_acc.legend()\n","  plt.show()\n","# show history\n","plot_history(history)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t_x4QXlZs6k0"},"source":["# Model Predictions and Scores"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kvtWTD0as5j-","colab":{}},"source":["from skimage.measure import compare_ssim\n","from sklearn.metrics import jaccard_similarity_score\n","from glob import glob\n","from PIL import Image as imgop\n","import cv2\n","import imageio \n","\n","img_dir = os.path.join(os.getcwd(),'test','images') \n","tgt_dir = os.path.join(os.getcwd(),'test','masks')\n","\n","def create_dir(base_dir,ext_name):\n","    '''\n","        creates a new dir with ext_name in base_dir and returns the path\n","    '''\n","    new_dir=os.path.join(base_dir,ext_name)\n","    if not os.path.exists(new_dir):\n","        os.mkdir(new_dir)\n","    return new_dir\n","\n","pred_path=create_dir(os.path.join(os.getcwd(),'test'),'preds')\n","pred_dir=create_dir(pred_path,iden)\n","\n","# preprocess data\n","def get_img(_path):\n","    data=imgop.open(_path)\n","    data=data.resize((IMG_DIM,IMG_DIM))\n","    data=np.array(data)\n","    data=data.astype('float32')/255.0\n","    data=np.expand_dims(data,axis=0)\n","    return data\n","\n","def get_gt(_path):\n","    # test folder mask path\n","    _mpath=str(_path).replace(\"images\",\"masks\")\n","    # ground truth\n","    gt=cv2.imread(_mpath,0)\n","    # resize\n","    gt= cv2.resize(gt,(IMG_DIM,IMG_DIM), interpolation = cv2.INTER_AREA)\n","    # Otsu's thresholding after Gaussian filtering\n","    blur = cv2.GaussianBlur(gt,(5,5),0)\n","    _,gt = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","    return gt\n","\n","def get_pred(model,img,_path):\n","    _ppath=str(_path).replace('images','preds/{}'.format(iden))\n","    pred=model.predict([img])\n","    pred =np.squeeze(pred)*255.0\n","    pred=pred.astype('uint8')\n","    imageio.imsave(_ppath,pred)\n","    pred=cv2.imread(_ppath,0)\n","    pred= cv2.resize(pred,(IMG_DIM,IMG_DIM), interpolation = cv2.INTER_AREA)\n","    # Otsu's thresholding after Gaussian filtering\n","    blur = cv2.GaussianBlur(pred,(5,5),0)\n","    _,pred = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","    return pred\n","\n","def get_overlay(pred,img):\n","    img=np.squeeze(img)\n","    overlay=img*0.2\n","    xs,ys=np.nonzero(pred)\n","    for x,y in zip(xs,ys):\n","        overlay[x,y,:]=img[x,y,:]\n","    \n","    return overlay\n","\n","\n","def get_score(pred,gt):\n","    (ssim_score,_) = compare_ssim(gt,pred,full=True)\n","    iou = jaccard_similarity_score(gt.flatten(), pred.flatten())\n","    return ssim_score,iou\n","\n","def score_summary(arr,model_name,score_iden):\n","    print(model_name,':',score_iden)\n","    print('max:',np.amax(arr))\n","    print('mean:',np.mean(arr))\n","    print('min:',np.amin(arr))\n","\n","# plotting data\n","def plot_data(img,gt,pred,overlay):\n","    fig, (ax1, ax2, ax3,ax4) = plt.subplots(1, 4,figsize=(20,20))\n","    ax1.imshow(np.squeeze(img))\n","    ax1.title.set_text('image')\n","    ax2.imshow(np.squeeze(gt))\n","    ax2.title.set_text('ground truth')\n","    ax3.imshow(np.squeeze(pred))\n","    ax3.title.set_text('prediction')\n","    ax4.imshow(np.squeeze(overlay))\n","    ax4.title.set_text('Overlay')\n","    plt.show()\n","\n","img_paths=glob(os.path.join(img_dir,'*.*'))\n","SSIM=[]\n","IOU=[]\n","# inference model\n","model_infer = sm.Unet(model_name,input_shape=(IMG_DIM,IMG_DIM,NB_CHANNEL), encoder_weights=None)\n","model_infer.load_weights(WEIGHT_PATH)\n","print('Loaded inference weights')\n","for _path in img_paths:\n","    # ground truth\n","    gt=get_gt(_path)\n","    # image\n","    img=get_img(_path) \n","    # prediction\n","    pred=get_pred(model_infer,img,_path)\n","    # overlay\n","    overlay=get_overlay(pred,img)\n","    # scores\n","    ssim_score,iou=get_score(pred,gt)\n","    SSIM.append(ssim_score)\n","    IOU.append(iou)\n","    plot_data(img,gt,pred,overlay)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uTfKWXsB4Z3u","colab_type":"text"},"source":["# Evaluation Scores"]},{"cell_type":"code","metadata":{"id":"JUtezCr631YM","colab_type":"code","colab":{}},"source":["score_summary(np.array(SSIM),model_name,'ssim')\n","score_summary(np.array(IOU),model_name,'IoU/F1')"],"execution_count":0,"outputs":[]}]}